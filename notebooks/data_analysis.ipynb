{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8348b76",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Analysis of UK National Grid demand data from NESO (National Energy System Operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from supabase import create_client, Client\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fa4d5",
   "metadata": {},
   "source": [
    "## Demand Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabecf41",
   "metadata": {},
   "source": [
    "| Column name                 | Description                                                                                              |\n",
    "| --------------------------- | -------------------------------------------------------------------------------------------------------- |\n",
    "| `SETTLEMENT_DATE`           | Calendar date of the electricity settlement period (UTC).                                                |\n",
    "| `SETTLEMENT_PERIOD`         | Half-hour settlement period within the day (1–48).                                                       |\n",
    "| `FORECAST_ACTUAL_INDICATOR` | Indicates whether the data point is **Actual (A)** or **Forecast (F)**.                                  |\n",
    "| `ND`                        | **National Demand** – estimated total GB electricity demand including embedded generation.               |\n",
    "| `TSD`                       | **Transmission System Demand** – demand seen by the transmission network (excludes embedded generation). |\n",
    "| `ENGLAND_WALES_DEMAND`      | Electricity demand specific to England and Wales.                                                        |\n",
    "| `EMBEDDED_WIND_GENERATION`  | Electricity generated by wind connected to distribution networks (not transmission).                     |\n",
    "| `EMBEDDED_WIND_CAPACITY`    | Installed capacity of embedded wind generation.                                                          |\n",
    "| `EMBEDDED_SOLAR_GENERATION` | Electricity generated by embedded solar PV.                                                              |\n",
    "| `EMBEDDED_SOLAR_CAPACITY`   | Installed capacity of embedded solar PV.                                                                 |\n",
    "| `NON_BM_STOR`               | Non-Balancing Mechanism storage output (e.g. small-scale batteries).                                     |\n",
    "| `PUMP_STORAGE_PUMPING`      | Electricity demand used to pump water into pumped-storage hydro (negative net generation).               |\n",
    "| `SCOTTISH_TRANSFER`         | Net electricity transfer between Scotland and England/Wales.                                             |\n",
    "| `IFA_FLOW`                  | Power flow on the **IFA** interconnector (GB–France).                                                    |\n",
    "| `IFA2_FLOW`                 | Power flow on the **IFA2** interconnector (GB–France).                                                   |\n",
    "| `BRITNED_FLOW`              | Power flow on the **BritNed** interconnector (GB–Netherlands).                                           |\n",
    "| `MOYLE_FLOW`                | Power flow on the **Moyle** interconnector (GB–Northern Ireland).                                        |\n",
    "| `EAST_WEST_FLOW`            | Power flow on the **East-West** interconnector (GB–Ireland).                                             |\n",
    "| `NEMO_FLOW`                 | Power flow on the **NEMO** interconnector (GB–Belgium).                                                  |\n",
    "| `NSL_FLOW`                  | Power flow on the **North Sea Link** interconnector (GB–Norway).                                         |\n",
    "| `ELECLINK_FLOW`             | Power flow on the **ElecLink** interconnector (GB–France).                                               |\n",
    "| `VIKING_FLOW`               | Power flow on the **Viking Link** interconnector (GB–Denmark).                                           |\n",
    "| `GREENLINK_FLOW`            | Power flow on the **Greenlink** interconnector (GB–Ireland).                                             |       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f095dd",
   "metadata": {},
   "source": [
    "### Download Historic Data\n",
    "Download CSV files for each year (2020-2025) from NESO data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db25a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase connection\n",
    "supabase_url: str = os.getenv(\"SUPABASE_URL\")\n",
    "supabase_key: str = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "print(\"Connected to Supabase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32039393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2020\n",
      "Loaded 17568 records from 2020\n",
      "  Date range: 2020-01-01 00:00:00 to 2020-12-31 00:00:00\n",
      "\n",
      "Processing 2021\n",
      "Loaded 17520 records from 2021\n",
      "  Date range: 2021-01-01 00:00:00 to 2021-12-31 00:00:00\n",
      "\n",
      "Processing 2022\n",
      "Loaded 17520 records from 2022\n",
      "  Date range: 2022-01-01 00:00:00 to 2022-12-31 00:00:00\n",
      "\n",
      "Processing 2023\n",
      "Loaded 17520 records from 2023\n",
      "  Date range: 2023-01-01 00:00:00 to 2023-12-31 00:00:00\n",
      "\n",
      "Processing 2024\n",
      "Loaded 17568 records from 2024\n",
      "  Date range: 2024-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "Processing 2025\n",
      "Loaded 16800 records from 2025\n",
      "  Date range: 2025-01-01 00:00:00 to 2025-12-16 00:00:00\n",
      "\n",
      "Done.\n",
      "Total unified records: 104496\n",
      "Final date range: 2020-01-01 00:00:00 to 2025-12-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BASE_PAGE = \"https://www.neso.energy/data-portal/historic-demand-data/historic_demand_data_{}\"\n",
    "YEARS = range(2020, 2026)\n",
    "OUT_DIR = Path(\"neso_historic_demand\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"academic-dashboard-project\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def sha256(path: Path) -> str:\n",
    "    \"\"\"Calculate SHA256 hash of a file for deduplication.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def standardize_date(date_val):\n",
    "    \"\"\"Convert various date formats to a standard datetime object.\"\"\"\n",
    "    if pd.isna(date_val):\n",
    "        return pd.NaT\n",
    "    \n",
    "    date_formats = [\n",
    "        '%Y-%m-%d',        # 2025-06-27\n",
    "        '%d-%b-%y',        # 26-Oct-23\n",
    "        '%d-%b-%Y',        # 26-Oct-2023\n",
    "        '%d-%B-%y',        # 26-October-23\n",
    "        '%d-%B-%Y',        # 26-October-2023\n",
    "        '%Y-%m-%dT%H:%M:%S.%fZ',\n",
    "        '%Y-%m-%dT%H:%M:%S',\n",
    "    ]\n",
    "    \n",
    "    date_str = str(date_val).strip().upper()\n",
    "    \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt.upper() if '%b' in fmt or '%B' in fmt else fmt)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        return pd.to_datetime(date_str, dayfirst=True)\n",
    "    except:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2cf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and process data for each year\n",
    "all_dfs = []\n",
    "seen_hashes = set()\n",
    "\n",
    "for year in YEARS:\n",
    "    print(f\"Processing {year}...\")\n",
    "    page_url = BASE_PAGE.format(year)\n",
    "\n",
    "    # Fetch dataset page\n",
    "    r = session.get(page_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Find CSV download link\n",
    "    csv_url = None\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"].lower()\n",
    "        if \"download\" in href and href.endswith(\".csv\"):\n",
    "            csv_url = a[\"href\"]\n",
    "            break\n",
    "\n",
    "    if not csv_url:\n",
    "        print(f\"  No CSV found for {year}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    if csv_url.startswith(\"/\"):\n",
    "        csv_url = \"https://www.neso.energy\" + csv_url\n",
    "\n",
    "    csv_path = OUT_DIR / f\"historic_demand_{year}.csv\"\n",
    "\n",
    "    # Download CSV\n",
    "    with session.get(csv_url, stream=True, timeout=60) as resp:\n",
    "        resp.raise_for_status()\n",
    "        with open(csv_path, \"wb\") as f:\n",
    "            for chunk in resp.iter_content(8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    # Verify uniqueness\n",
    "    file_hash = sha256(csv_path)\n",
    "    if file_hash in seen_hashes:\n",
    "        print(f\"  Duplicate detected for {year}, skipping...\")\n",
    "        continue\n",
    "    seen_hashes.add(file_hash)\n",
    "\n",
    "    # Load and standardize date format\n",
    "    df_year = pd.read_csv(csv_path)\n",
    "    df_year['SETTLEMENT_DATE'] = df_year['SETTLEMENT_DATE'].apply(standardize_date)\n",
    "    df_year[\"SOURCE_YEAR\"] = year\n",
    "\n",
    "    all_dfs.append(df_year)\n",
    "    print(f\"  Loaded {len(df_year)} records ({df_year['SETTLEMENT_DATE'].min().date()} to {df_year['SETTLEMENT_DATE'].max().date()})\")\n",
    "\n",
    "# Combine all years\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "print(f\"\\nTotal records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD', 'ND', 'TSD', 'ENGLAND_WALES_DEMAND', 'EMBEDDED_WIND_GENERATION', 'EMBEDDED_WIND_CAPACITY', 'EMBEDDED_SOLAR_GENERATION', 'EMBEDDED_SOLAR_CAPACITY', 'NON_BM_STOR', 'PUMP_STORAGE_PUMPING', 'IFA_FLOW', 'IFA2_FLOW', 'BRITNED_FLOW', 'MOYLE_FLOW', 'EAST_WEST_FLOW', 'NEMO_FLOW', 'NSL_FLOW', 'ELECLINK_FLOW', 'VIKING_FLOW', 'GREENLINK_FLOW', 'SOURCE_YEAR', 'SCOTTISH_TRANSFER']\n",
      "Total rows: 104496\n",
      "Date range: 01-APR-2020 to 31-Oct-23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SETTLEMENT_DATE</th>\n",
       "      <th>SETTLEMENT_PERIOD</th>\n",
       "      <th>ND</th>\n",
       "      <th>TSD</th>\n",
       "      <th>ENGLAND_WALES_DEMAND</th>\n",
       "      <th>EMBEDDED_WIND_GENERATION</th>\n",
       "      <th>EMBEDDED_WIND_CAPACITY</th>\n",
       "      <th>EMBEDDED_SOLAR_GENERATION</th>\n",
       "      <th>EMBEDDED_SOLAR_CAPACITY</th>\n",
       "      <th>NON_BM_STOR</th>\n",
       "      <th>...</th>\n",
       "      <th>BRITNED_FLOW</th>\n",
       "      <th>MOYLE_FLOW</th>\n",
       "      <th>EAST_WEST_FLOW</th>\n",
       "      <th>NEMO_FLOW</th>\n",
       "      <th>NSL_FLOW</th>\n",
       "      <th>ELECLINK_FLOW</th>\n",
       "      <th>VIKING_FLOW</th>\n",
       "      <th>GREENLINK_FLOW</th>\n",
       "      <th>SOURCE_YEAR</th>\n",
       "      <th>SCOTTISH_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-JAN-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>26340</td>\n",
       "      <td>27153</td>\n",
       "      <td>23821</td>\n",
       "      <td>1073</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>852</td>\n",
       "      <td>-151</td>\n",
       "      <td>-47</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-JAN-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>26921</td>\n",
       "      <td>27684</td>\n",
       "      <td>24393</td>\n",
       "      <td>1020</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>853</td>\n",
       "      <td>-146</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-JAN-2020</td>\n",
       "      <td>3</td>\n",
       "      <td>26569</td>\n",
       "      <td>27240</td>\n",
       "      <td>24085</td>\n",
       "      <td>1010</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>852</td>\n",
       "      <td>-53</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-JAN-2020</td>\n",
       "      <td>4</td>\n",
       "      <td>25754</td>\n",
       "      <td>26435</td>\n",
       "      <td>23350</td>\n",
       "      <td>1043</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>852</td>\n",
       "      <td>-66</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-JAN-2020</td>\n",
       "      <td>5</td>\n",
       "      <td>25075</td>\n",
       "      <td>25824</td>\n",
       "      <td>22788</td>\n",
       "      <td>1001</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>853</td>\n",
       "      <td>-74</td>\n",
       "      <td>-60</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SETTLEMENT_DATE  SETTLEMENT_PERIOD     ND    TSD  ENGLAND_WALES_DEMAND  \\\n",
       "0     01-JAN-2020                  1  26340  27153                 23821   \n",
       "1     01-JAN-2020                  2  26921  27684                 24393   \n",
       "2     01-JAN-2020                  3  26569  27240                 24085   \n",
       "3     01-JAN-2020                  4  25754  26435                 23350   \n",
       "4     01-JAN-2020                  5  25075  25824                 22788   \n",
       "\n",
       "   EMBEDDED_WIND_GENERATION  EMBEDDED_WIND_CAPACITY  \\\n",
       "0                      1073                    6465   \n",
       "1                      1020                    6465   \n",
       "2                      1010                    6465   \n",
       "3                      1043                    6465   \n",
       "4                      1001                    6465   \n",
       "\n",
       "   EMBEDDED_SOLAR_GENERATION  EMBEDDED_SOLAR_CAPACITY  NON_BM_STOR  ...  \\\n",
       "0                          0                    13040            0  ...   \n",
       "1                          0                    13040            0  ...   \n",
       "2                          0                    13040            0  ...   \n",
       "3                          0                    13040            0  ...   \n",
       "4                          0                    13040            0  ...   \n",
       "\n",
       "   BRITNED_FLOW  MOYLE_FLOW  EAST_WEST_FLOW  NEMO_FLOW  NSL_FLOW  \\\n",
       "0           852        -151             -47        854         0   \n",
       "1           853        -146               0        854         0   \n",
       "2           852         -53               0        854         0   \n",
       "3           852         -66               0        854         0   \n",
       "4           853         -74             -60        854         0   \n",
       "\n",
       "   ELECLINK_FLOW  VIKING_FLOW  GREENLINK_FLOW  SOURCE_YEAR  SCOTTISH_TRANSFER  \n",
       "0              0            0               0         2020                NaN  \n",
       "1              0            0               0         2020                NaN  \n",
       "2              0            0               0         2020                NaN  \n",
       "3              0            0               0         2020                NaN  \n",
       "4              0            0               0         2020                NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Date range: {df['SETTLEMENT_DATE'].min()} to {df['SETTLEMENT_DATE'].max()}\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07850a0f",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Remove unnecessary columns and create a unified datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned columns: ['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD', 'ND', 'TSD', 'ENGLAND_WALES_DEMAND', 'EMBEDDED_WIND_GENERATION', 'EMBEDDED_WIND_CAPACITY', 'EMBEDDED_SOLAR_GENERATION', 'EMBEDDED_SOLAR_CAPACITY', 'NON_BM_STOR', 'PUMP_STORAGE_PUMPING', 'SCOTTISH_TRANSFER', 'IFA_FLOW', 'IFA2_FLOW', 'BRITNED_FLOW', 'MOYLE_FLOW', 'EAST_WEST_FLOW', 'NEMO_FLOW', 'NSL_FLOW', 'ELECLINK_FLOW', 'VIKING_FLOW', 'GREENLINK_FLOW']\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "columns_to_remove = ['_id', '_full_text', '_count', 'rank', 'FORECAST_ACTUAL_INDICATOR', 'SOURCE_YEAR']\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns], errors='ignore')\n",
    "\n",
    "# Filter for actual data only (not forecasts)\n",
    "if 'FORECAST_ACTUAL_INDICATOR' in df.columns:\n",
    "    df_cleaned = df[df['FORECAST_ACTUAL_INDICATOR'] == 'A'].copy()\n",
    "    df_cleaned = df_cleaned.drop(columns=['FORECAST_ACTUAL_INDICATOR'], errors='ignore')\n",
    "\n",
    "print(f\"Columns after cleaning: {df_cleaned.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d05c5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime range: 2025-12-01 00:00:00 to 2026-01-13 23:30:00\n"
     ]
    }
   ],
   "source": [
    "# Create unified DATETIME column from SETTLEMENT_DATE and SETTLEMENT_PERIOD\n",
    "# Each settlement period is 30 minutes (period 1 = 00:00-00:30)\n",
    "df_cleaned['DATETIME'] = df_cleaned.apply(\n",
    "    lambda row: row['SETTLEMENT_DATE'] + timedelta(minutes=(int(row['SETTLEMENT_PERIOD']) - 1) * 30),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Reorder columns and remove original date columns\n",
    "cols = ['DATETIME'] + [col for col in df_cleaned.columns if col not in ['DATETIME', 'SETTLEMENT_DATE', 'SETTLEMENT_PERIOD']]\n",
    "df_cleaned = df_cleaned[cols]\n",
    "\n",
    "print(f\"Final shape: {df_cleaned.shape}\")\n",
    "print(f\"Date range: {df_cleaned['DATETIME'].min()} to {df_cleaned['DATETIME'].max()}\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e096b2",
   "metadata": {},
   "source": [
    "### Upload to Supabase\n",
    "Insert the cleaned data into the Supabase database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58242410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Supabase\n",
    "df_to_insert = df_cleaned.copy()\n",
    "df_to_insert['DATETIME'] = df_to_insert['DATETIME'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_to_insert.columns = df_to_insert.columns.str.lower()\n",
    "data_to_insert = df_to_insert.to_dict(orient='records')\n",
    "\n",
    "# Insert in batches\n",
    "batch_size = 500\n",
    "total_inserted = 0\n",
    "\n",
    "print(f\"Inserting {len(data_to_insert)} records...\")\n",
    "\n",
    "for i in range(0, len(data_to_insert), batch_size):\n",
    "    batch = data_to_insert[i:i + batch_size]\n",
    "    try:\n",
    "        response = supabase.table(\"demand_data\").upsert(batch).execute()\n",
    "        total_inserted += len(batch)\n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"Progress: {total_inserted}/{len(data_to_insert)} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error at batch {i // batch_size + 1}: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nCompleted! Total records inserted: {total_inserted}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
