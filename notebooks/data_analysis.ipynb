{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8348b76",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Analysis of UK National Grid demand data from NESO (National Energy System Operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "559bc6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from supabase import create_client, Client\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fa4d5",
   "metadata": {},
   "source": [
    "## Demand Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabecf41",
   "metadata": {},
   "source": [
    "| Column name                 | Description                                                                                              |\n",
    "| --------------------------- | -------------------------------------------------------------------------------------------------------- |\n",
    "| `SETTLEMENT_DATE`           | Calendar date of the electricity settlement period (UTC).                                                |\n",
    "| `SETTLEMENT_PERIOD`         | Half-hour settlement period within the day (1–48).                                                       |\n",
    "| `FORECAST_ACTUAL_INDICATOR` | Indicates whether the data point is **Actual (A)** or **Forecast (F)**.                                  |\n",
    "| `ND`                        | **National Demand** – estimated total GB electricity demand including embedded generation.               |\n",
    "| `TSD`                       | **Transmission System Demand** – demand seen by the transmission network (excludes embedded generation). |\n",
    "| `ENGLAND_WALES_DEMAND`      | Electricity demand specific to England and Wales.                                                        |\n",
    "| `EMBEDDED_WIND_GENERATION`  | Electricity generated by wind connected to distribution networks (not transmission).                     |\n",
    "| `EMBEDDED_WIND_CAPACITY`    | Installed capacity of embedded wind generation.                                                          |\n",
    "| `EMBEDDED_SOLAR_GENERATION` | Electricity generated by embedded solar PV.                                                              |\n",
    "| `EMBEDDED_SOLAR_CAPACITY`   | Installed capacity of embedded solar PV.                                                                 |\n",
    "| `NON_BM_STOR`               | Non-Balancing Mechanism storage output (e.g. small-scale batteries).                                     |\n",
    "| `PUMP_STORAGE_PUMPING`      | Electricity demand used to pump water into pumped-storage hydro (negative net generation).               |\n",
    "| `SCOTTISH_TRANSFER`         | Net electricity transfer between Scotland and England/Wales.                                             |\n",
    "| `IFA_FLOW`                  | Power flow on the **IFA** interconnector (GB–France).                                                    |\n",
    "| `IFA2_FLOW`                 | Power flow on the **IFA2** interconnector (GB–France).                                                   |\n",
    "| `BRITNED_FLOW`              | Power flow on the **BritNed** interconnector (GB–Netherlands).                                           |\n",
    "| `MOYLE_FLOW`                | Power flow on the **Moyle** interconnector (GB–Northern Ireland).                                        |\n",
    "| `EAST_WEST_FLOW`            | Power flow on the **East-West** interconnector (GB–Ireland).                                             |\n",
    "| `NEMO_FLOW`                 | Power flow on the **NEMO** interconnector (GB–Belgium).                                                  |\n",
    "| `NSL_FLOW`                  | Power flow on the **North Sea Link** interconnector (GB–Norway).                                         |\n",
    "| `ELECLINK_FLOW`             | Power flow on the **ElecLink** interconnector (GB–France).                                               |\n",
    "| `VIKING_FLOW`               | Power flow on the **Viking Link** interconnector (GB–Denmark).                                           |\n",
    "| `GREENLINK_FLOW`            | Power flow on the **Greenlink** interconnector (GB–Ireland).                                             |       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f095dd",
   "metadata": {},
   "source": [
    "### Download Historic Data\n",
    "Download CSV files for each year (2020-2025) from NESO data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db25a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase connection\n",
    "supabase_url: str = os.getenv(\"SUPABASE_URL\")\n",
    "supabase_key: str = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "print(\"Connected to Supabase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "075caad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_PAGE = \"https://www.neso.energy/data-portal/historic-demand-data/historic_demand_data_{}\"\n",
    "YEARS = range(2020, 2026)\n",
    "OUT_DIR = Path(\"neso_historic_demand\")\n",
    "OUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32039393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP session with custom User-Agent\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"academic-dashboard-project\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70450424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def sha256(path: Path) -> str:\n",
    "    \"\"\"Calculate SHA256 hash of a file for deduplication.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20e53e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define possible date formats globally\n",
    "date_formats = [\n",
    "    '%Y-%m-%d',        # 2025-06-27\n",
    "    '%d-%b-%y',        # 26-Oct-23\n",
    "    '%d-%b-%Y',        # 26-Oct-2023\n",
    "    '%d-%B-%y',        # 26-October-23\n",
    "    '%d-%B-%Y',        # 26-October-2023\n",
    "    '%Y-%m-%dT%H:%M:%S.%fZ',\n",
    "    '%Y-%m-%dT%H:%M:%S',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a92c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_date(date_val):\n",
    "    \"\"\"Convert various date formats to a standard datetime object.\"\"\"\n",
    "    if pd.isna(date_val):\n",
    "        return pd.NaT\n",
    "    \n",
    "    date_str = str(date_val).strip().upper()\n",
    "    \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt.upper() if '%b' in fmt or '%B' in fmt else fmt)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        return pd.to_datetime(date_str, dayfirst=True)\n",
    "    except:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b2cf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2020...\n",
      "  Loaded 17568 records (2020-01-01 to 2020-12-31)\n",
      "Processing 2021...\n",
      "  Loaded 17520 records (2021-01-01 to 2021-12-31)\n",
      "Processing 2022...\n",
      "  Loaded 17520 records (2022-01-01 to 2022-12-31)\n",
      "Processing 2023...\n",
      "  Loaded 17520 records (2023-01-01 to 2023-12-31)\n",
      "Processing 2024...\n",
      "  Loaded 17568 records (2024-01-01 to 2024-12-31)\n",
      "Processing 2025...\n",
      "  Loaded 16800 records (2025-01-01 to 2025-12-16)\n",
      "\n",
      "Total records: 104496\n"
     ]
    }
   ],
   "source": [
    "# Download and process data for each year\n",
    "all_dfs = []\n",
    "seen_hashes = set()\n",
    "\n",
    "for year in YEARS:\n",
    "    print(f\"Processing {year}...\")\n",
    "    page_url = BASE_PAGE.format(year)\n",
    "\n",
    "    # Fetch dataset page\n",
    "    r = session.get(page_url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Find CSV download link\n",
    "    csv_url = None\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"].lower()\n",
    "        if \"download\" in href and href.endswith(\".csv\"):\n",
    "            csv_url = a[\"href\"]\n",
    "            break\n",
    "\n",
    "    if not csv_url:\n",
    "        print(f\"  No CSV found for {year}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    if csv_url.startswith(\"/\"):\n",
    "        csv_url = \"https://www.neso.energy\" + csv_url\n",
    "\n",
    "    csv_path = OUT_DIR / f\"historic_demand_{year}.csv\"\n",
    "\n",
    "    # Download CSV\n",
    "    with session.get(csv_url, stream=True, timeout=60) as resp:\n",
    "        resp.raise_for_status()\n",
    "        with open(csv_path, \"wb\") as f:\n",
    "            for chunk in resp.iter_content(8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    # Verify uniqueness\n",
    "    file_hash = sha256(csv_path)\n",
    "    if file_hash in seen_hashes:\n",
    "        print(f\"  Duplicate detected for {year}, skipping...\")\n",
    "        continue\n",
    "    seen_hashes.add(file_hash)\n",
    "\n",
    "    # Load and standardize date format\n",
    "    df_year = pd.read_csv(csv_path)\n",
    "    df_year['SETTLEMENT_DATE'] = df_year['SETTLEMENT_DATE'].apply(standardize_date)\n",
    "    df_year[\"SOURCE_YEAR\"] = year\n",
    "\n",
    "    all_dfs.append(df_year)\n",
    "    print(f\"  Loaded {len(df_year)} records ({df_year['SETTLEMENT_DATE'].min().date()} to {df_year['SETTLEMENT_DATE'].max().date()})\")\n",
    "\n",
    "# Combine all years\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "print(f\"\\nTotal records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a45a4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD', 'ND', 'TSD', 'ENGLAND_WALES_DEMAND', 'EMBEDDED_WIND_GENERATION', 'EMBEDDED_WIND_CAPACITY', 'EMBEDDED_SOLAR_GENERATION', 'EMBEDDED_SOLAR_CAPACITY', 'NON_BM_STOR', 'PUMP_STORAGE_PUMPING', 'IFA_FLOW', 'IFA2_FLOW', 'BRITNED_FLOW', 'MOYLE_FLOW', 'EAST_WEST_FLOW', 'NEMO_FLOW', 'NSL_FLOW', 'ELECLINK_FLOW', 'VIKING_FLOW', 'GREENLINK_FLOW', 'SOURCE_YEAR', 'SCOTTISH_TRANSFER']\n",
      "Date range: 2020-01-01 00:00:00 to 2025-12-16 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SETTLEMENT_DATE</th>\n",
       "      <th>SETTLEMENT_PERIOD</th>\n",
       "      <th>ND</th>\n",
       "      <th>TSD</th>\n",
       "      <th>ENGLAND_WALES_DEMAND</th>\n",
       "      <th>EMBEDDED_WIND_GENERATION</th>\n",
       "      <th>EMBEDDED_WIND_CAPACITY</th>\n",
       "      <th>EMBEDDED_SOLAR_GENERATION</th>\n",
       "      <th>EMBEDDED_SOLAR_CAPACITY</th>\n",
       "      <th>NON_BM_STOR</th>\n",
       "      <th>...</th>\n",
       "      <th>BRITNED_FLOW</th>\n",
       "      <th>MOYLE_FLOW</th>\n",
       "      <th>EAST_WEST_FLOW</th>\n",
       "      <th>NEMO_FLOW</th>\n",
       "      <th>NSL_FLOW</th>\n",
       "      <th>ELECLINK_FLOW</th>\n",
       "      <th>VIKING_FLOW</th>\n",
       "      <th>GREENLINK_FLOW</th>\n",
       "      <th>SOURCE_YEAR</th>\n",
       "      <th>SCOTTISH_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34286</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>15</td>\n",
       "      <td>32405</td>\n",
       "      <td>35654</td>\n",
       "      <td>30075</td>\n",
       "      <td>2568</td>\n",
       "      <td>6527</td>\n",
       "      <td>0</td>\n",
       "      <td>14001</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>375</td>\n",
       "      <td>369</td>\n",
       "      <td>-587</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80737</th>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>4</td>\n",
       "      <td>17125</td>\n",
       "      <td>21825</td>\n",
       "      <td>16386</td>\n",
       "      <td>3448</td>\n",
       "      <td>6563</td>\n",
       "      <td>0</td>\n",
       "      <td>18053</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-301</td>\n",
       "      <td>-526</td>\n",
       "      <td>-958</td>\n",
       "      <td>-429</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>3247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90348</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>13</td>\n",
       "      <td>26637</td>\n",
       "      <td>30627</td>\n",
       "      <td>25087</td>\n",
       "      <td>2087</td>\n",
       "      <td>6606</td>\n",
       "      <td>0</td>\n",
       "      <td>19726</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1071</td>\n",
       "      <td>-131</td>\n",
       "      <td>0</td>\n",
       "      <td>-632</td>\n",
       "      <td>1397</td>\n",
       "      <td>850</td>\n",
       "      <td>-1094</td>\n",
       "      <td>-439</td>\n",
       "      <td>2025</td>\n",
       "      <td>4377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32542</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>47</td>\n",
       "      <td>24344</td>\n",
       "      <td>25771</td>\n",
       "      <td>23057</td>\n",
       "      <td>2649</td>\n",
       "      <td>6527</td>\n",
       "      <td>0</td>\n",
       "      <td>13915</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>924</td>\n",
       "      <td>122</td>\n",
       "      <td>-65</td>\n",
       "      <td>584</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22657</th>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>24955</td>\n",
       "      <td>26196</td>\n",
       "      <td>22744</td>\n",
       "      <td>382</td>\n",
       "      <td>6527</td>\n",
       "      <td>0</td>\n",
       "      <td>13653</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SETTLEMENT_DATE  SETTLEMENT_PERIOD     ND    TSD  ENGLAND_WALES_DEMAND  \\\n",
       "34286      2021-12-15                 15  32405  35654                 30075   \n",
       "80737      2024-08-09                  4  17125  21825                 16386   \n",
       "90348      2025-02-25                 13  26637  30627                 25087   \n",
       "32542      2021-11-08                 47  24344  25771                 23057   \n",
       "22657      2021-04-17                  4  24955  26196                 22744   \n",
       "\n",
       "       EMBEDDED_WIND_GENERATION  EMBEDDED_WIND_CAPACITY  \\\n",
       "34286                      2568                    6527   \n",
       "80737                      3448                    6563   \n",
       "90348                      2087                    6606   \n",
       "32542                      2649                    6527   \n",
       "22657                       382                    6527   \n",
       "\n",
       "       EMBEDDED_SOLAR_GENERATION  EMBEDDED_SOLAR_CAPACITY  NON_BM_STOR  ...  \\\n",
       "34286                          0                    14001            0  ...   \n",
       "80737                          0                    18053            0  ...   \n",
       "90348                          0                    19726            0  ...   \n",
       "32542                          0                    13915            0  ...   \n",
       "22657                          0                    13653            0  ...   \n",
       "\n",
       "       BRITNED_FLOW  MOYLE_FLOW  EAST_WEST_FLOW  NEMO_FLOW  NSL_FLOW  \\\n",
       "34286           108         375             369       -587       693   \n",
       "80737             0        -301            -526       -958      -429   \n",
       "90348         -1071        -131               0       -632      1397   \n",
       "32542           924         122             -65        584       693   \n",
       "22657             0         -19               0        975         0   \n",
       "\n",
       "       ELECLINK_FLOW  VIKING_FLOW  GREENLINK_FLOW  SOURCE_YEAR  \\\n",
       "34286              0            0               0         2021   \n",
       "80737            159            0               0         2024   \n",
       "90348            850        -1094            -439         2025   \n",
       "32542              0            0               0         2021   \n",
       "22657              0            0               0         2021   \n",
       "\n",
       "       SCOTTISH_TRANSFER  \n",
       "34286                NaN  \n",
       "80737             3247.0  \n",
       "90348             4377.0  \n",
       "32542                NaN  \n",
       "22657                NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Date range: {df['SETTLEMENT_DATE'].min()} to {df['SETTLEMENT_DATE'].max()}\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07850a0f",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Remove unnecessary columns and create a unified datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2db1a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after cleaning: ['SETTLEMENT_DATE', 'SETTLEMENT_PERIOD', 'ND', 'TSD', 'ENGLAND_WALES_DEMAND', 'EMBEDDED_WIND_GENERATION', 'EMBEDDED_WIND_CAPACITY', 'EMBEDDED_SOLAR_GENERATION', 'EMBEDDED_SOLAR_CAPACITY', 'NON_BM_STOR', 'PUMP_STORAGE_PUMPING', 'IFA_FLOW', 'IFA2_FLOW', 'BRITNED_FLOW', 'MOYLE_FLOW', 'EAST_WEST_FLOW', 'NEMO_FLOW', 'NSL_FLOW', 'ELECLINK_FLOW', 'VIKING_FLOW', 'GREENLINK_FLOW', 'SCOTTISH_TRANSFER']\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "columns_to_remove = ['_id', '_full_text', '_count', 'rank', 'FORECAST_ACTUAL_INDICATOR', 'SOURCE_YEAR']\n",
    "df_cleaned = df.drop(columns=[col for col in columns_to_remove if col in df.columns], errors='ignore')\n",
    "\n",
    "print(f\"Columns after cleaning: {df_cleaned.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d05c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unified DATETIME column from SETTLEMENT_DATE and SETTLEMENT_PERIOD\n",
    "df_cleaned['DATETIME'] = df_cleaned.apply(\n",
    "    lambda row: row['SETTLEMENT_DATE'] + timedelta(minutes=(int(row['SETTLEMENT_PERIOD']) - 1) * 30),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c34d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns and remove original date columns\n",
    "cols = ['DATETIME'] + [col for col in df_cleaned.columns if col not in ['DATETIME', 'SETTLEMENT_DATE', 'SETTLEMENT_PERIOD']]\n",
    "df_cleaned = df_cleaned[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c859416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (104496, 21)\n",
      "Date range: 2020-01-01 00:00:00 to 2025-12-16 23:30:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>ND</th>\n",
       "      <th>TSD</th>\n",
       "      <th>ENGLAND_WALES_DEMAND</th>\n",
       "      <th>EMBEDDED_WIND_GENERATION</th>\n",
       "      <th>EMBEDDED_WIND_CAPACITY</th>\n",
       "      <th>EMBEDDED_SOLAR_GENERATION</th>\n",
       "      <th>EMBEDDED_SOLAR_CAPACITY</th>\n",
       "      <th>NON_BM_STOR</th>\n",
       "      <th>PUMP_STORAGE_PUMPING</th>\n",
       "      <th>...</th>\n",
       "      <th>IFA2_FLOW</th>\n",
       "      <th>BRITNED_FLOW</th>\n",
       "      <th>MOYLE_FLOW</th>\n",
       "      <th>EAST_WEST_FLOW</th>\n",
       "      <th>NEMO_FLOW</th>\n",
       "      <th>NSL_FLOW</th>\n",
       "      <th>ELECLINK_FLOW</th>\n",
       "      <th>VIKING_FLOW</th>\n",
       "      <th>GREENLINK_FLOW</th>\n",
       "      <th>SCOTTISH_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>26340</td>\n",
       "      <td>27153</td>\n",
       "      <td>23821</td>\n",
       "      <td>1073</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "      <td>-151</td>\n",
       "      <td>-47</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:30:00</td>\n",
       "      <td>26921</td>\n",
       "      <td>27684</td>\n",
       "      <td>24393</td>\n",
       "      <td>1020</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>-146</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>26569</td>\n",
       "      <td>27240</td>\n",
       "      <td>24085</td>\n",
       "      <td>1010</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "      <td>-53</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 01:30:00</td>\n",
       "      <td>25754</td>\n",
       "      <td>26435</td>\n",
       "      <td>23350</td>\n",
       "      <td>1043</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "      <td>-66</td>\n",
       "      <td>0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>25075</td>\n",
       "      <td>25824</td>\n",
       "      <td>22788</td>\n",
       "      <td>1001</td>\n",
       "      <td>6465</td>\n",
       "      <td>0</td>\n",
       "      <td>13040</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>-74</td>\n",
       "      <td>-60</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATETIME     ND    TSD  ENGLAND_WALES_DEMAND  \\\n",
       "0 2020-01-01 00:00:00  26340  27153                 23821   \n",
       "1 2020-01-01 00:30:00  26921  27684                 24393   \n",
       "2 2020-01-01 01:00:00  26569  27240                 24085   \n",
       "3 2020-01-01 01:30:00  25754  26435                 23350   \n",
       "4 2020-01-01 02:00:00  25075  25824                 22788   \n",
       "\n",
       "   EMBEDDED_WIND_GENERATION  EMBEDDED_WIND_CAPACITY  \\\n",
       "0                      1073                    6465   \n",
       "1                      1020                    6465   \n",
       "2                      1010                    6465   \n",
       "3                      1043                    6465   \n",
       "4                      1001                    6465   \n",
       "\n",
       "   EMBEDDED_SOLAR_GENERATION  EMBEDDED_SOLAR_CAPACITY  NON_BM_STOR  \\\n",
       "0                          0                    13040            0   \n",
       "1                          0                    13040            0   \n",
       "2                          0                    13040            0   \n",
       "3                          0                    13040            0   \n",
       "4                          0                    13040            0   \n",
       "\n",
       "   PUMP_STORAGE_PUMPING  ...  IFA2_FLOW  BRITNED_FLOW  MOYLE_FLOW  \\\n",
       "0                    15  ...          0           852        -151   \n",
       "1                    17  ...          0           853        -146   \n",
       "2                    18  ...          0           852         -53   \n",
       "3                    15  ...          0           852         -66   \n",
       "4                    15  ...          0           853         -74   \n",
       "\n",
       "   EAST_WEST_FLOW  NEMO_FLOW  NSL_FLOW  ELECLINK_FLOW  VIKING_FLOW  \\\n",
       "0             -47        854         0              0            0   \n",
       "1               0        854         0              0            0   \n",
       "2               0        854         0              0            0   \n",
       "3               0        854         0              0            0   \n",
       "4             -60        854         0              0            0   \n",
       "\n",
       "   GREENLINK_FLOW  SCOTTISH_TRANSFER  \n",
       "0               0                NaN  \n",
       "1               0                NaN  \n",
       "2               0                NaN  \n",
       "3               0                NaN  \n",
       "4               0                NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(f\"Final shape: {df_cleaned.shape}\")\n",
    "print(f\"Date range: {df_cleaned['DATETIME'].min()} to {df_cleaned['DATETIME'].max()}\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890afe9",
   "metadata": {},
   "source": [
    "## Data Quality\n",
    "\n",
    "Analyse the data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f4d3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104,496 records\n",
      "From 2020-01-01 00:00:00 to 2025-12-16 23:30:00\n",
      "\n",
      "21 columns: ['DATETIME', 'ND', 'TSD', 'ENGLAND_WALES_DEMAND', 'EMBEDDED_WIND_GENERATION', 'EMBEDDED_WIND_CAPACITY', 'EMBEDDED_SOLAR_GENERATION', 'EMBEDDED_SOLAR_CAPACITY', 'NON_BM_STOR', 'PUMP_STORAGE_PUMPING', 'IFA_FLOW', 'IFA2_FLOW', 'BRITNED_FLOW', 'MOYLE_FLOW', 'EAST_WEST_FLOW', 'NEMO_FLOW', 'NSL_FLOW', 'ELECLINK_FLOW', 'VIKING_FLOW', 'GREENLINK_FLOW', 'SCOTTISH_TRANSFER']\n"
     ]
    }
   ],
   "source": [
    "# Quick overview\n",
    "print(f\"{len(df_cleaned):,} records\")\n",
    "print(f\"From {df_cleaned['DATETIME'].min()} to {df_cleaned['DATETIME'].max()}\")\n",
    "print(f\"\\n{len(df_cleaned.columns)} columns: {df_cleaned.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f09db7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "SCOTTISH_TRANSFER    52608\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect Missing values\n",
    "missing = df_cleaned.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "if len(missing) > 0:\n",
    "    print(\"Missing values:\")\n",
    "    print(missing)\n",
    "else:\n",
    "    print(\"No nulls detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52b4d68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 duplicate timestamps\n"
     ]
    }
   ],
   "source": [
    "# Detect duplicates\n",
    "dupes = df_cleaned[df_cleaned.duplicated(subset=['DATETIME'], keep=False)]\n",
    "print(f\"{len(dupes)} duplicate timestamps\")\n",
    "\n",
    "if len(dupes) > 0:\n",
    "    dupes.sort_values('DATETIME').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f9621fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates \n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=['DATETIME'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46e7010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicate timestamps\n"
     ]
    }
   ],
   "source": [
    "# Make sure duplicates are dropped \n",
    "dupes = df_cleaned[df_cleaned.duplicated(subset=['DATETIME'], keep=False)]\n",
    "print(f\"{len(dupes)} duplicate timestamps\")\n",
    "\n",
    "if len(dupes) > 0:\n",
    "    dupes.sort_values('DATETIME').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b81f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 gaps in the time series\n"
     ]
    }
   ],
   "source": [
    "# Check for gaps\n",
    "df_sorted = df_cleaned.sort_values('DATETIME')\n",
    "time_diffs = df_sorted['DATETIME'].diff()\n",
    "gaps = time_diffs[time_diffs > timedelta(minutes=30)]\n",
    "\n",
    "print(f\"Found {len(gaps)} gaps in the time series\")\n",
    "\n",
    "if len(gaps) > 0:\n",
    "    # show the biggest ones\n",
    "    gap_df = pd.DataFrame({\n",
    "        'starts_after': df_sorted.loc[gaps.index - 1, 'DATETIME'].values,\n",
    "        'duration': gaps.values\n",
    "    }).sort_values('duration', ascending=False)\n",
    "    gap_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe4758f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>ND</th>\n",
       "      <th>TSD</th>\n",
       "      <th>ENGLAND_WALES_DEMAND</th>\n",
       "      <th>EMBEDDED_WIND_GENERATION</th>\n",
       "      <th>EMBEDDED_WIND_CAPACITY</th>\n",
       "      <th>EMBEDDED_SOLAR_GENERATION</th>\n",
       "      <th>EMBEDDED_SOLAR_CAPACITY</th>\n",
       "      <th>NON_BM_STOR</th>\n",
       "      <th>PUMP_STORAGE_PUMPING</th>\n",
       "      <th>...</th>\n",
       "      <th>IFA2_FLOW</th>\n",
       "      <th>BRITNED_FLOW</th>\n",
       "      <th>MOYLE_FLOW</th>\n",
       "      <th>EAST_WEST_FLOW</th>\n",
       "      <th>NEMO_FLOW</th>\n",
       "      <th>NSL_FLOW</th>\n",
       "      <th>ELECLINK_FLOW</th>\n",
       "      <th>VIKING_FLOW</th>\n",
       "      <th>GREENLINK_FLOW</th>\n",
       "      <th>SCOTTISH_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104484</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>104484.000000</td>\n",
       "      <td>51882.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-12-24 11:59:25.165958400</td>\n",
       "      <td>26752.066833</td>\n",
       "      <td>28717.435081</td>\n",
       "      <td>24515.319637</td>\n",
       "      <td>1884.021745</td>\n",
       "      <td>6549.374163</td>\n",
       "      <td>1583.656388</td>\n",
       "      <td>15890.782924</td>\n",
       "      <td>0.421529</td>\n",
       "      <td>192.440192</td>\n",
       "      <td>...</td>\n",
       "      <td>251.905842</td>\n",
       "      <td>276.472618</td>\n",
       "      <td>-144.414886</td>\n",
       "      <td>-94.521946</td>\n",
       "      <td>409.267141</td>\n",
       "      <td>590.256030</td>\n",
       "      <td>220.793031</td>\n",
       "      <td>115.522893</td>\n",
       "      <td>-51.194355</td>\n",
       "      <td>1810.682877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>12803.000000</td>\n",
       "      <td>15297.000000</td>\n",
       "      <td>12040.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>6465.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13040.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1030.000000</td>\n",
       "      <td>-1093.000000</td>\n",
       "      <td>-505.000000</td>\n",
       "      <td>-585.000000</td>\n",
       "      <td>-1024.000000</td>\n",
       "      <td>-1455.000000</td>\n",
       "      <td>-1028.000000</td>\n",
       "      <td>-1465.000000</td>\n",
       "      <td>-539.000000</td>\n",
       "      <td>-2851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-06-28 06:22:30</td>\n",
       "      <td>21879.000000</td>\n",
       "      <td>24206.000000</td>\n",
       "      <td>20047.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>6527.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13721.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>-444.000000</td>\n",
       "      <td>-374.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-12-24 11:45:00</td>\n",
       "      <td>25866.000000</td>\n",
       "      <td>27788.000000</td>\n",
       "      <td>23665.000000</td>\n",
       "      <td>1552.000000</td>\n",
       "      <td>6545.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15029.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>-207.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>693.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024-06-20 18:07:30</td>\n",
       "      <td>30673.000000</td>\n",
       "      <td>32349.250000</td>\n",
       "      <td>28132.000000</td>\n",
       "      <td>2622.000000</td>\n",
       "      <td>6562.000000</td>\n",
       "      <td>2540.250000</td>\n",
       "      <td>17714.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>941.000000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>1395.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3223.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-12-16 23:30:00</td>\n",
       "      <td>46433.000000</td>\n",
       "      <td>47760.000000</td>\n",
       "      <td>42458.000000</td>\n",
       "      <td>5962.000000</td>\n",
       "      <td>6622.000000</td>\n",
       "      <td>14035.000000</td>\n",
       "      <td>20993.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>1869.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1419.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>6704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6219.736766</td>\n",
       "      <td>5932.001775</td>\n",
       "      <td>5693.937458</td>\n",
       "      <td>1213.376734</td>\n",
       "      <td>38.492120</td>\n",
       "      <td>2484.195058</td>\n",
       "      <td>2550.415513</td>\n",
       "      <td>10.005025</td>\n",
       "      <td>362.019887</td>\n",
       "      <td>...</td>\n",
       "      <td>624.826686</td>\n",
       "      <td>656.898443</td>\n",
       "      <td>281.493949</td>\n",
       "      <td>302.518871</td>\n",
       "      <td>625.839242</td>\n",
       "      <td>702.943795</td>\n",
       "      <td>553.844066</td>\n",
       "      <td>493.307370</td>\n",
       "      <td>162.808656</td>\n",
       "      <td>1854.728008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            DATETIME             ND            TSD  \\\n",
       "count                         104484  104484.000000  104484.000000   \n",
       "mean   2022-12-24 11:59:25.165958400   26752.066833   28717.435081   \n",
       "min              2020-01-01 00:00:00   12803.000000   15297.000000   \n",
       "25%              2021-06-28 06:22:30   21879.000000   24206.000000   \n",
       "50%              2022-12-24 11:45:00   25866.000000   27788.000000   \n",
       "75%              2024-06-20 18:07:30   30673.000000   32349.250000   \n",
       "max              2025-12-16 23:30:00   46433.000000   47760.000000   \n",
       "std                              NaN    6219.736766    5932.001775   \n",
       "\n",
       "       ENGLAND_WALES_DEMAND  EMBEDDED_WIND_GENERATION  EMBEDDED_WIND_CAPACITY  \\\n",
       "count         104484.000000             104484.000000           104484.000000   \n",
       "mean           24515.319637               1884.021745             6549.374163   \n",
       "min            12040.000000                125.000000             6465.000000   \n",
       "25%            20047.000000                910.000000             6527.000000   \n",
       "50%            23665.000000               1552.000000             6545.000000   \n",
       "75%            28132.000000               2622.000000             6562.000000   \n",
       "max            42458.000000               5962.000000             6622.000000   \n",
       "std             5693.937458               1213.376734               38.492120   \n",
       "\n",
       "       EMBEDDED_SOLAR_GENERATION  EMBEDDED_SOLAR_CAPACITY    NON_BM_STOR  \\\n",
       "count              104484.000000            104484.000000  104484.000000   \n",
       "mean                 1583.656388             15890.782924       0.421529   \n",
       "min                     0.000000             13040.000000       0.000000   \n",
       "25%                     0.000000             13721.000000       0.000000   \n",
       "50%                     6.000000             15029.000000       0.000000   \n",
       "75%                  2540.250000             17714.000000       0.000000   \n",
       "max                 14035.000000             20993.000000     481.000000   \n",
       "std                  2484.195058              2550.415513      10.005025   \n",
       "\n",
       "       PUMP_STORAGE_PUMPING  ...      IFA2_FLOW   BRITNED_FLOW     MOYLE_FLOW  \\\n",
       "count         104484.000000  ...  104484.000000  104484.000000  104484.000000   \n",
       "mean             192.440192  ...     251.905842     276.472618    -144.414886   \n",
       "min                0.000000  ...   -1030.000000   -1093.000000    -505.000000   \n",
       "25%                7.000000  ...      -2.000000    -104.000000    -444.000000   \n",
       "50%               11.000000  ...       0.000000     346.000000    -207.000000   \n",
       "75%              157.000000  ...     941.000000     917.000000      81.000000   \n",
       "max             1869.000000  ...    1016.000000    1080.000000     499.000000   \n",
       "std              362.019887  ...     624.826686     656.898443     281.493949   \n",
       "\n",
       "       EAST_WEST_FLOW      NEMO_FLOW       NSL_FLOW  ELECLINK_FLOW  \\\n",
       "count   104484.000000  104484.000000  104484.000000  104484.000000   \n",
       "mean       -94.521946     409.267141     590.256030     220.793031   \n",
       "min       -585.000000   -1024.000000   -1455.000000   -1028.000000   \n",
       "25%       -374.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.000000     667.000000     693.000000       0.000000   \n",
       "75%          0.000000     963.000000    1395.000000     871.000000   \n",
       "max        504.000000    1020.000000    1419.000000    1002.000000   \n",
       "std        302.518871     625.839242     702.943795     553.844066   \n",
       "\n",
       "         VIKING_FLOW  GREENLINK_FLOW  SCOTTISH_TRANSFER  \n",
       "count  104484.000000   104484.000000       51882.000000  \n",
       "mean      115.522893      -51.194355        1810.682877  \n",
       "min     -1465.000000     -539.000000       -2851.000000  \n",
       "25%         0.000000        0.000000         281.250000  \n",
       "50%         0.000000        0.000000        1664.000000  \n",
       "75%         0.000000        0.000000        3223.000000  \n",
       "max      1436.000000      506.000000        6704.000000  \n",
       "std       493.307370      162.808656        1854.728008  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "587e9255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ND: 237 outliers (0.2%)\n",
      "TSD: 509 outliers (0.5%)\n",
      "ENGLAND_WALES_DEMAND: 207 outliers (0.2%)\n"
     ]
    }
   ],
   "source": [
    "# Outliers - using IQR on the main demand columns\n",
    "for col in ['ND', 'TSD', 'ENGLAND_WALES_DEMAND']:\n",
    "    if col not in df_cleaned.columns:\n",
    "        continue\n",
    "    q1, q3 = df_cleaned[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    outliers = df_cleaned[(df_cleaned[col] < q1 - 1.5*iqr) | (df_cleaned[col] > q3 + 1.5*iqr)]\n",
    "    print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df_cleaned)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cbdf718d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>records</th>\n",
       "      <th>expected</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>17566</td>\n",
       "      <td>17520</td>\n",
       "      <td>100.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>17518</td>\n",
       "      <td>17520</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>17518</td>\n",
       "      <td>17520</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>17518</td>\n",
       "      <td>17520</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>17566</td>\n",
       "      <td>17520</td>\n",
       "      <td>100.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>16798</td>\n",
       "      <td>17520</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          records  expected    pct\n",
       "DATETIME                          \n",
       "2020        17566     17520  100.3\n",
       "2021        17518     17520  100.0\n",
       "2022        17518     17520  100.0\n",
       "2023        17518     17520  100.0\n",
       "2024        17566     17520  100.3\n",
       "2025        16798     17520   95.9"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How complete is each year? (expecting 48 periods/day × 365 days)\n",
    "expected = 48 * 365\n",
    "\n",
    "by_year = df_cleaned.groupby(df_cleaned['DATETIME'].dt.year).size()\n",
    "completeness = pd.DataFrame({\n",
    "    'records': by_year,\n",
    "    'expected': expected,\n",
    "    'pct': (by_year / expected * 100).round(1)\n",
    "})\n",
    "completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae10eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 104,484\n",
      "Nulls: 52602\n",
      "Dupelicates: 0\n",
      "Range: 2020-01-01 → 2025-12-16\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "nulls = df_cleaned.isnull().sum().sum()\n",
    "dupes = df_cleaned.duplicated(subset=['DATETIME']).sum()\n",
    "\n",
    "print(f\"Records: {len(df_cleaned):,}\")\n",
    "print(f\"Nulls: {nulls}\")\n",
    "print(f\"Dupelicates: {dupes}\")\n",
    "print(f\"Range: {df_cleaned['DATETIME'].min().date()} → {df_cleaned['DATETIME'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d637bbac",
   "metadata": {},
   "source": [
    "## Upload to Supabase\n",
    "\n",
    "Uplaod the cleaned data to the remote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57c59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc5c5176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Supabase.\n"
     ]
    }
   ],
   "source": [
    "# Define keys and client\n",
    "supabase_url: str = os.getenv(\"SUPABASE_URL\")\n",
    "supabase_key: str = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "print(\"Connected to Supabase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a73695",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Out of range float values are not JSON compliant: nan",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m end = \u001b[38;5;28mmin\u001b[39m(start + batch_size, \u001b[38;5;28mlen\u001b[39m(df_upload))\n\u001b[32m     13\u001b[39m batch = df_upload.iloc[start:end].to_dict(orient=\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m response = \u001b[43msupabase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhistoric_demand\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\postgrest\\_sync\\request_builder.py:47\u001b[39m, in \u001b[36mSyncQueryRequestBuilder.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> APIResponse:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the query.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    .. tip::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \u001b[33;03m        :class:`APIError` If the API raised an error.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m r.is_success:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\postgrest\\base_request_builder.py:81\u001b[39m, in \u001b[36mRequestConfig.send\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend\u001b[39m(\u001b[38;5;28mself\u001b[39m: RequestConfig[C]):\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\httpx\\_client.py:812\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    805\u001b[39m     message = (\n\u001b[32m    806\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSetting per-request cookies=<...> is being deprecated, because \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    807\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe expected behaviour on cookie persistence is ambiguous. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    808\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcookies directly on the client instance instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    809\u001b[39m     )\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\httpx\\_client.py:378\u001b[39m, in \u001b[36mBaseClient.build_request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, timeout, extensions)\u001b[39m\n\u001b[32m    372\u001b[39m     timeout = (\n\u001b[32m    373\u001b[39m         \u001b[38;5;28mself\u001b[39m.timeout\n\u001b[32m    374\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timeout, UseClientDefault)\n\u001b[32m    375\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m Timeout(timeout)\n\u001b[32m    376\u001b[39m     )\n\u001b[32m    377\u001b[39m     extensions = \u001b[38;5;28mdict\u001b[39m(**extensions, timeout=timeout.as_dict())\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\httpx\\_models.py:408\u001b[39m, in \u001b[36mRequest.__init__\u001b[39m\u001b[34m(self, method, url, params, headers, cookies, content, data, files, json, stream, extensions)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     content_type: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mself\u001b[39m.headers.get(\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     headers, stream = \u001b[43mencode_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_multipart_boundary_from_content_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare(headers)\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\httpx\\_content.py:216\u001b[39m, in \u001b[36mencode_request\u001b[39m\u001b[34m(content, data, files, json, boundary)\u001b[39m\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m encode_urlencoded_data(data)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m json \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {}, ByteStream(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abudi\\Personal Projects\\IOT451U-25-A2-ec25737\\env\\Lib\\site-packages\\httpx\\_content.py:177\u001b[39m, in \u001b[36mencode_json\u001b[39m\u001b[34m(json)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_json\u001b[39m(json: Any) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], ByteStream]:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     body = \u001b[43mjson_dumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m     content_length = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(body))\n\u001b[32m    181\u001b[39m     content_type = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\json\\encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\json\\encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Out of range float values are not JSON compliant: nan"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Prep for upload\n",
    "df_upload = df_cleaned.copy()\n",
    "df_upload['DATETIME'] = df_upload['DATETIME'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_upload.columns = df_upload.columns.str.lower()\n",
    "\n",
    "# Replace NaN and inf with None\n",
    "df_upload = df_upload.replace([np.nan, np.inf, -np.inf], None)\n",
    "\n",
    "# Batch upload\n",
    "batch_size = 1000\n",
    "for start in range(0, len(df_upload), batch_size):\n",
    "    end = min(start + batch_size, len(df_upload))\n",
    "    batch = df_upload.iloc[start:end].to_dict(orient='records')\n",
    "    \n",
    "    # Extra cleanup - convert any remaining nan to None\n",
    "    for record in batch:\n",
    "        for key, val in record.items():\n",
    "            if isinstance(val, float) and (np.isnan(val) or np.isinf(val)):\n",
    "                record[key] = None\n",
    "    \n",
    "    response = supabase.table('historic_demand').insert(batch).execute()\n",
    "    print(f\"Uploaded {start} to {end}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
